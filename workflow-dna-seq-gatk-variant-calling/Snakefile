import os
import numpy as np
import pandas as pd

# load configuration
# -----------------------------------------------------
configfile: "config/config.yml"

# read sample sheet
samples = (
    pd.read_csv(config["samplesheet"], sep="\t", dtype={"sample": str, "lane": str})
    .set_index(["sample", "lane"], drop=False)
)

FASTQC_HTML_OUTPUTS = [
    os.path.join("results/qc/fastqc", f"{row.sample}.L{row.lane}.{read}.html")
    for row in samples.itertuples(index=False)
    for read in ["r1", "r2"]
]

FASTQC_ZIP_OUTPUTS = [
    os.path.join("results/qc/fastqc", f"{row.sample}.L{row.lane}.{read}_fastqc.zip")
    for row in samples.itertuples(index=False)
    for read in ["r1", "r2"]
]

MAPPING_OUTPUTS = [
    os.path.join("results/mapped", f"{row.sample}-{row.lane}.sorted.bam")
    for row in samples.itertuples(index=False)
]

DEDUP_OUTPUTS = [
    os.path.join("results/dedup", f"{row.sample}-{row.lane}.bam")
    for row in samples.itertuples(index=False)
]

localrules: multiqc_fastqc

# target rules
# -----------------------------------------------------
rule all:
    input:
        "reports/multiqc/fastqc.html",
        "results/multiqc/fastqc_data.zip",
        "results/merge/all.biallelic.bcf",

rule fastqc:
    input:
        lookup(query="sample == '{sample}' & lane == '{lane}'", within=samples, cols="{read}")
    output:
        html="results/qc/fastqc/{sample}.L{lane}.{read}.html",
        zip="results/qc/fastqc/{sample}.L{lane}.{read}_fastqc.zip", # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename
    params:
        extra = "--quiet"
    log:
        "logs/fastqc/{sample}.{lane}.{read}.log"
    threads: 1
    resources:
        mem_mb=1024,
    wrapper:
        "v5.7.0/bio/fastqc"

rule multiqc_fastqc:
    input:
        FASTQC_HTML_OUTPUTS,
        FASTQC_ZIP_OUTPUTS,
    output:
        "reports/multiqc/fastqc.html",
        "results/multiqc/fastqc_data.zip",
    params:
        extra="--verbose",  # Optional: extra parameters for multiqc.
    log:
        "logs/multiqc.log",
    wrapper:
        "v8.1.1/bio/multiqc"

def get_fastq(wildcards):
    """Get fastq files of given sample-lane."""
    fastqs = samples.loc[(wildcards.sample, wildcards.lane), ["r1", "r2"]].dropna()
    return [fastqs.r1, fastqs.r2]

rule map_reads:
    input:
        reads=get_fastq,
        idx=multiext(config["bwa"]["index"], ".amb", ".ann", ".bwt", ".pac", ".sa"),
    output:
        temp("results/mapped/{sample}-{lane}.sorted.bam"),
    log:
        "logs/bwa_mem/{sample}-{lane}.log",
    params:
        extra=r"-R '@RG\tID:{sample}\tSM:{sample}'",
        sorting="samtools",  # Can be 'none', 'samtools' or 'picard'.
        sort_order="coordinate",  # Can be 'queryname' or 'coordinate'.
        sort_extra="",  # Extra args for samtools/picard.
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bwa/mem"

rule mark_duplicates:
    input:
        bams="results/mapped/{sample}-{lane}.sorted.bam",
    output:
        bam=temp("results/dedup/{sample}-{lane}.bam"),
        metrics="results/qc/dedup/{sample}-{lane}.metrics.txt",
    log:
        "logs/picard/dedup/{sample}-{lane}.log",
    params:
        extra="--REMOVE_DUPLICATES true",
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/picard/markduplicates"

rule bcftools_mpileup:
    input:
        alignments=expand("results/dedup/{sample}-{lane}.bam", sample="{sample}", lane=lookup(query="sample == '{sample}'", within=samples, cols="lane")),
        ref=config["genome"]["fasta"],
        index=config["genome"]["fasta"] + ".fai",
    output:
        pileup="results/pileups/{sample}.bcf",
    params:
        uncompressed_bcf=False,
        extra="", # e.g. --max-depth 100 --min-BQ 15
    log:
        "logs/bcftools_mpileup/{sample}.log",
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/mpileup"

rule bcftools_call:
    input:
        pileup="results/pileups/{sample}.bcf",
    output:
        calls="results/calls/{sample}.bcf",
    params:
        uncompressed_bcf=False,
        caller="-m",  # valid options include -c/--consensus-caller or -m/--multiallelic-caller
        extra="--ploidy 2 --prior 0.01", # TODO: switch ploidy to 1 for mitochondria and Y chromosome (unless those chromosomes are excluded from the analysis)
    log:
        "logs/bcftools_call/{sample}.log",
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/call"

rule bcftools_index:
    input:
        "results/calls/{sample}.bcf",
    output:
        "results/calls/{sample}.bcf.csi",
    log:
        "logs/bcftools_index/{sample}.log",
    params:
        extra="",  # optional parameters for bcftools index
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/index"

rule bcftools_merge:
    input:
        calls=expand("results/calls/{sample}.bcf", sample=samples['sample'].unique()),
        idx=expand("results/calls/{sample}.bcf.csi", sample=samples['sample'].unique()),
    output:
        "results/merge/all.bcf",
    log:
        "logs/bcftools_merge/all.log",
    params:
        uncompressed_bcf=False,
        extra="",  # optional parameters for bcftools concat (except -o)
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/merge"

# rename to filter_snps
rule bcftools_filter_biallelic:
    input:
        "results/merge/all.bcf",
    output:
        "results/merge/all.biallelic.bcf",
    log:
        "logs/bcftools_filter_biallelic.log",
    params:
        extra="--include 'QUAL>=30' --exclude-types indels",
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/view"