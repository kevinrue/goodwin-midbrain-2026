import os
import numpy as np
import pandas as pd

# load configuration
# -----------------------------------------------------
configfile: "config/config.yml"

# read sample sheet
samples = (
    pd.read_csv(config["samplesheet"], sep="\t", dtype={"sample": str, "lane": str})
    .set_index(["sample", "lane"], drop=False)
)

FASTQC_HTML_OUTPUTS = [
    os.path.join("results/qc/fastqc", f"{row.sample}.L{row.lane}.{read}.html")
    for row in samples.itertuples(index=False)
    for read in ["r1", "r2"]
]

FASTQC_ZIP_OUTPUTS = [
    os.path.join("results/qc/fastqc", f"{row.sample}.L{row.lane}.{read}_fastqc.zip")
    for row in samples.itertuples(index=False)
    for read in ["r1", "r2"]
]

MAPPING_OUTPUTS = [
    os.path.join("results/mapped", f"{row.sample}-{row.lane}.sorted.bam")
    for row in samples.itertuples(index=False)
]

DEDUP_OUTPUTS = [
    os.path.join("results/dedup", f"{row.sample}-{row.lane}.bam")
    for row in samples.itertuples(index=False)
]

localrules: multiqc_fastqc

# target rules
# -----------------------------------------------------
rule all:
    input:
        "reports/multiqc/fastqc.html",
        "results/multiqc/fastqc_data.zip",
        "results/merge/filtered.snps.vcf.gz.tbi",
        "results/genotype_gvcfs/filtered.snps.vcf.gz.tbi",

rule fastqc:
    input:
        lookup(query="sample == '{sample}' & lane == '{lane}'", within=samples, cols="{read}")
    output:
        html="results/qc/fastqc/{sample}.L{lane}.{read}.html",
        zip="results/qc/fastqc/{sample}.L{lane}.{read}_fastqc.zip", # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename
    params:
        extra = "--quiet"
    log:
        "logs/fastqc/{sample}.{lane}.{read}.log"
    threads: 1
    resources:
        mem_mb=1024,
    wrapper:
        "v5.7.0/bio/fastqc"

rule multiqc_fastqc:
    input:
        FASTQC_HTML_OUTPUTS,
        FASTQC_ZIP_OUTPUTS,
    output:
        "reports/multiqc/fastqc.html",
        "results/multiqc/fastqc_data.zip",
    params:
        extra="--verbose",  # Optional: extra parameters for multiqc.
    log:
        "logs/multiqc.log",
    wrapper:
        "v8.1.1/bio/multiqc"

def get_fastq(wildcards):
    """Get fastq files of given sample-lane."""
    fastqs = samples.loc[(wildcards.sample, wildcards.lane), ["r1", "r2"]].dropna()
    return [fastqs.r1, fastqs.r2]

rule map_reads:
    input:
        reads=get_fastq,
        idx=multiext(config["bwa"]["index"], ".amb", ".ann", ".bwt", ".pac", ".sa"),
    output:
        temp("results/mapped/{sample}-{lane}.sorted.bam"),
    log:
        "logs/bwa_mem/{sample}-{lane}.log",
    params:
        extra=r"-R '@RG\tID:{sample}\tSM:{sample}'",
        sorting="samtools",  # Can be 'none', 'samtools' or 'picard'.
        sort_order="coordinate",  # Can be 'queryname' or 'coordinate'.
        sort_extra="",  # Extra args for samtools/picard.
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bwa/mem"

rule mark_duplicates:
    input:
        bams="results/mapped/{sample}-{lane}.sorted.bam",
    output:
        bam=protected("results/dedup/{sample}-{lane}.bam"),
        metrics="results/qc/dedup/{sample}-{lane}.metrics.txt",
    log:
        "logs/picard/dedup/{sample}-{lane}.log",
    params:
        extra="--REMOVE_DUPLICATES true",
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/picard/markduplicates"

rule bcftools_mpileup:
    input:
        alignments=expand(
            "results/dedup/{sample}-{lane}.bam",
            sample="{sample}",
            lane=lookup(query="sample == '{sample}'", within=samples, cols="lane")
            ),
        ref=config["genome"]["fasta"],
        index=config["genome"]["fasta"] + ".fai",
    output:
        pileup="results/pileups/{sample}.bcf",
    params:
        uncompressed_bcf=False,
        extra="", # e.g. --max-depth 100 --min-BQ 15
    log:
        "logs/bcftools_mpileup/{sample}.log",
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/mpileup"

rule bcftools_call:
    input:
        pileup="results/pileups/{sample}.bcf",
    output:
        calls="results/calls/{sample}.bcf",
    params:
        uncompressed_bcf=False,
        caller="-m",  # valid options include -c/--consensus-caller or -m/--multiallelic-caller
        extra="--ploidy 2 --prior 0.01", # TODO: switch ploidy to 1 for mitochondria and Y chromosome (unless those chromosomes are excluded from the analysis)
    log:
        "logs/bcftools_call/{sample}.log",
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/call"

rule bcftools_index:
    input:
        "results/calls/{sample}.bcf",
    output:
        "results/calls/{sample}.bcf.csi",
    log:
        "logs/bcftools_index/{sample}.log",
    params:
        extra="",  # optional parameters for bcftools index
    threads: 8
    resources:
        mem="16G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/index"

rule bcftools_merge:
    input:
        calls=expand("results/calls/{sample}.bcf", sample=samples['sample'].unique()),
        idx=expand("results/calls/{sample}.bcf.csi", sample=samples['sample'].unique()),
    output:
        "results/merge/all.bcf",
    log:
        "logs/bcftools_merge/all.log",
    params:
        uncompressed_bcf=False,
        extra="",  # optional parameters for bcftools concat (except -o)
    threads: 8
    resources:
        mem="8G",
        runtime="1h",
    wrapper:
        "v9.0.0/bio/bcftools/merge"

rule bcftools_filter:
    input:
        "results/merge/all.bcf",
        targets=config["bcftools"]["targets"],
    output:
        "results/merge/filtered.snps.vcf.gz",
    log:
        "logs/bcftools_filter.log",
    params:
        extra="-m2 -M2 --include 'QUAL>=30 && FMT/GT=\"het\"' --types snps",
    threads: 8
    resources:
        mem="8G",
        runtime="5m",
    wrapper:
        "v9.0.0/bio/bcftools/view"

rule tabix:
    input:
        "results/merge/filtered.snps.vcf.gz",
    output:
        "results/merge/filtered.snps.vcf.gz.tbi",
    log:
        "logs/tabix.log",
    params:
        # pass arguments to tabix (e.g. index a vcf)
        "-p vcf",
    threads: 1
    resources:
        mem="8G",
        runtime="5m",
    wrapper:
        "v9.0.0/bio/tabix/index"

rule samtools_index:
    input:
        "results/dedup/{sample}-{lane}.bam",
    output:
        protected("results/dedup/{sample}-{lane}.bam.bai"),
    log:
        "logs/samtools_index/{sample}-{lane}.log",
    params:
        extra="",  # optional parameters for samtools index
    threads: 8
    resources:
        mem="8G",
        runtime="30m",
    wrapper:
        "v9.0.0/bio/samtools/index"

rule haplotype_caller:
    input:
        bam=expand(
            "results/dedup/{sample}-{lane}.bam",
            sample="{sample}",
            lane=lookup(query="sample == '{sample}'", within=samples, cols="lane")
            ),
        bai=expand(
            "results/dedup/{sample}-{lane}.bam.bai",
            sample="{sample}",
            lane=lookup(query="sample == '{sample}'", within=samples, cols="lane")
            ),
        ref=config["genome"]["fasta"],
    output:
        gvcf="results/haplotype_caller/{sample}.g.vcf.gz",
    params:
        extra="",  # optional
        java_opts="",  # optional
    log:
        "logs/haplotype_caller/{sample}.log",
    threads: 8 # https://github.com/snakemake/snakemake-wrappers/issues/4937
    resources:
        mem="8G",
        runtime="4h",
    wrapper:
        "file:///ceph/project/goodwin/albrecht/snakemake-wrappers/bio/gatk/haplotypecaller" # "v9.0.0/bio/gatk/haplotypecaller"

rule haplotype_caller_merge:
    input:
        gvcfs=expand(
            "results/haplotype_caller/{sample}.g.vcf.gz",
            sample=samples['sample'].unique()
        ),
        ref=config["genome"]["fasta"],
    output:
        gvcf="results/haplotype_caller_merge/all.g.vcf.gz",
    log:
        "logs/haplotype_caller_merge.log",
    params:
        extra="",  # optional
        java_opts="",  # optional
    threads: 8 # https://github.com/snakemake/snakemake-wrappers/issues/4937
    resources:
        mem="8G",
        runtime="2h",
    wrapper:
        "v9.0.0/bio/gatk/combinegvcfs"

rule genotype_gvcfs:
    input:
        gvcf="results/haplotype_caller_merge/all.g.vcf.gz",  # combined gvcf over multiple samples
    # N.B. gvcf or genomicsdb must be specified
    # in the latter case, this is a GenomicsDB data store
        ref=config["genome"]["fasta"],
    output:
        vcf="results/genotype_gvcfs/all.vcf.gz",
    log:
        "logs/gatk/genotypegvcfs.log",
    params:
        extra="",  # optional --sample-ploidy 2
        java_opts="", # optional
    threads: 8 # https://github.com/snakemake/snakemake-wrappers/issues/4937
    resources:
        mem="8G",
        runtime="4h",
    wrapper:
        "v9.0.0/bio/gatk/genotypegvcfs"

rule genotype_gvcfs_filter:
    input:
        "results/genotype_gvcfs/all.vcf.gz",
        targets=config["bcftools"]["targets"],
    output:
        "results/genotype_gvcfs/filtered.snps.vcf.gz",
    log:
        "logs/genotype_gvcfs_filter.log",
    params:
        extra="-m2 -M2 --include 'QUAL>=30 && FMT/GT=\"het\"' --types snps",
    threads: 8
    resources:
        mem="8G",
        runtime="5m",
    wrapper:
        "v9.0.0/bio/bcftools/view"

rule genotype_gvcfs_tabix:
    input:
        "results/genotype_gvcfs/filtered.snps.vcf.gz",
    output:
        "results/genotype_gvcfs/filtered.snps.vcf.gz.tbi",
    log:
        "logs/genotype_gvcfs_tabix.log",
    params:
        # pass arguments to tabix (e.g. index a vcf)
        "-p vcf",
    threads: 1
    resources:
        mem="8G",
        runtime="5m",
    wrapper:
        "v9.0.0/bio/tabix/index"
